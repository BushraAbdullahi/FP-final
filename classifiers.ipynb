{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: accelerate in ./venv/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: imblearn in ./venv/lib/python3.11/site-packages (0.0)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.11/site-packages (4.33.1)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (1.25.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: seaborn in ./venv/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: wordcloud in ./venv/lib/python3.11/site-packages (1.9.2)\n",
      "Requirement already satisfied: xgboost in ./venv/lib/python3.11/site-packages (1.7.6)\n",
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: imbalanced-learn in ./venv/lib/python3.11/site-packages (from imblearn) (0.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in ./venv/lib/python3.11/site-packages (from transformers) (0.17.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.11/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.11/site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.11/site-packages (from xgboost) (1.11.2)\n",
      "Collecting pybind11>=2.2 (from fasttext)\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in ./venv/lib/python3.11/site-packages (from fasttext) (68.0.0)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp311-cp311-macosx_13_0_x86_64.whl size=356798 sha256=930e57d485ec7b365bee9f2d7cbfc87378dbd0634c7b45369c6d79d2a97d2575\n",
      "  Stored in directory: /Users/bushraabdullahi/Library/Caches/pip/wheels/12/89/c9/c932d04c4dd65abe347bbb3e6f7668688753cbc585305ad8b7\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torch accelerate imblearn transformers nltk pandas numpy matplotlib seaborn wordcloud xgboost fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = \"preprocessed_data.csv\"\n",
    "\n",
    "preprocessed_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "preprocessed_df[\"text\"].fillna(\"\", inplace=True)\n",
    "preprocessed_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9580441640378549\n",
      "Precision: 0.9546313799621928\n",
      "Recall: 0.9612944162436549\n",
      "F1-score: 0.9579513120455264\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(preprocessed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training text\n",
    "vectorizer.fit(train_df[\"text\"])\n",
    "\n",
    "# Transform the training and test text into TF-IDF feature vectors\n",
    "train_tfidf = vectorizer.transform(train_df[\"text\"])\n",
    "test_tfidf = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# Get the corresponding labels\n",
    "train_labels = train_df[\"label\"]\n",
    "test_labels = test_df[\"label\"]\n",
    "\n",
    "# Train a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(test_tfidf)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9034700315457413\n",
      "Precision: 0.9810606060606061\n",
      "Recall: 0.8217005076142132\n",
      "F1-score: 0.8943370165745858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(preprocessed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training text\n",
    "vectorizer.fit(train_df[\"text\"])\n",
    "\n",
    "# Transform the training and test text into TF-IDF feature vectors\n",
    "train_tfidf = vectorizer.transform(train_df[\"text\"])\n",
    "test_tfidf = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# Get the corresponding labels\n",
    "train_labels = train_df[\"label\"]\n",
    "test_labels = test_df[\"label\"]\n",
    "\n",
    "# Train a Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(test_tfidf)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9643533123028392\n",
      "Precision: 0.963855421686747\n",
      "Recall: 0.9644670050761421\n",
      "F1-score: 0.9641611163970821\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(preprocessed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training text\n",
    "vectorizer.fit(train_df[\"text\"])\n",
    "\n",
    "# Transform the training and test text into TF-IDF feature vectors\n",
    "train_tfidf = vectorizer.transform(train_df[\"text\"])\n",
    "test_tfidf = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# Get the corresponding labels\n",
    "train_labels = train_df[\"label\"]\n",
    "test_labels = test_df[\"label\"]\n",
    "\n",
    "# Train a Support Vector Machine (SVM) classifier\n",
    "classifier = SVC(kernel='linear')  # You can specify different kernels like 'linear', 'rbf', etc.\n",
    "classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(test_tfidf)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9394321766561514\n",
      "Precision: 0.9588859416445623\n",
      "Recall: 0.9175126903553299\n",
      "F1-score: 0.9377431906614785\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(preprocessed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training text\n",
    "vectorizer.fit(train_df[\"text\"])\n",
    "\n",
    "# Transform the training and test text into TF-IDF feature vectors\n",
    "train_tfidf = vectorizer.transform(train_df[\"text\"])\n",
    "test_tfidf = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# Get the corresponding labels\n",
    "train_labels = train_df[\"label\"]\n",
    "test_labels = test_df[\"label\"]\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "classifier = RandomForestClassifier()  # Initialize RandomForestClassifier\n",
    "classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(test_tfidf)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bushraabdullahi/Library/CloudStorage/OneDrive-Personal/Uni/L6/Final Project/FP-final/venv/lib/python3.11/site-packages/xgboost/data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9719242902208202\n",
      "Precision: 0.9667294413057125\n",
      "Recall: 0.9771573604060914\n",
      "F1-score: 0.9719154307352478\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(preprocessed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training text\n",
    "vectorizer.fit(train_df[\"text\"])\n",
    "\n",
    "# Transform the training and test text into TF-IDF feature vectors\n",
    "train_tfidf = vectorizer.transform(train_df[\"text\"])\n",
    "test_tfidf = vectorizer.transform(test_df[\"text\"])\n",
    "\n",
    "# Get the corresponding labels\n",
    "train_labels = train_df[\"label\"]\n",
    "test_labels = test_df[\"label\"]\n",
    "\n",
    "# Train an XGBoost classifier\n",
    "classifier = xgb.XGBClassifier()  # Initialize XGBoost classifier\n",
    "classifier.fit(train_tfidf, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(test_tfidf)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18a029f34de569bc87a5b20bf3524e89bed39c69b1af6c862570a3b15f046199"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
